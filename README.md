# Data Engineer

### Education
Masters of Technology in Software Engineering

### Work Experience
Data Engineer @ WinZO Games Pvt. Limited
- Scalable Data Pipeline Management: **Optimized** data processing pipelines using Apache Spark, handling 100+ TB of data daily to support 60 million user transactions with low-latency access.
Designed and implemented Databricks workflows to process and analyze large-scale data, ensuring optimized performance and scalability for real-time business needs. Collaborated with data scientists and analysts to deliver clean and accessible datasets for advanced analytics and reporting. Automated CI/CD workflows for ETL pipelines, enabling seamless deployment and reducing time-to-production by 30
- Spark Job Monitoring and Alerting: Developed an advanced monitoring system for Spark batch jobs using Pushgateway and Prometheus, enabling real-time alerting and comprehensive monitoring of Spark job health. This system has drastically improved job reliability and response times, ensuring proactive issue resolution across large-scale data workflows.
- Cost and Performance Optimization: Led a POC comparing Spark Jobs on EKS with EMR clusters, analyzing cost-efficiency and core-hour metrics to inform resource allocation strategies. Migrated complex batch pipelines to AWS Kubernetes, ensuring scalability, cost-efficiency, and robust cloud architecture.
- Enhanced Data Quality with Complex Ingestion Pipelines: Built and managed complex CDC ingestion pipelines with robust data integrity checks, and alerting mechanisms, processing 600+ million daily updates via Kafka. Migrated real-time Cassandra ingestion from EMR to AWS ECS, leveraging Docker for improved scalability and operational efficiency.
- Kafka Streaming: Developed and maintained real-time data pipelines using Kafka Streams, enabling reliable ingestion of 600+ million daily updates with advanced enrichment and deduplication mechanisms.

Data Engineer @ SG Analytics
- Built scalable ETL pipelines to extract, transform, and load structured and semi-structured data into Redshift for analytics teams. Developed Python-based scripts to automate data integration tasks and improve pipeline reliability, achieving 20 Designed and implemented SQL-based solutions for complex business queries, improving report generation performance by 50
- Assisted in data modeling and created a comprehensive database design, providing a foundation for database development. Leveraged Tableau to deliver performance insights, enhancing operational efficiency and decision-making.

### Projects
- Scalable Big Data Processing System using Microservices and Istio Developed a microservices-based big data processing system using Kafka, Spark Streaming, and Cassandra, managed through Istio for secure and efficient service communication
   - Microservices Implementation: Designed and deployed microservices for data ingestion, processing, and storage using Docker and Kubernetes, enabling scalable and modular architecture.
   - Real-time Data Processing: Implemented Apache Spark Streaming in Scala to process real-time data streams from Kafka, achieving low-latency and high-throughput processing.
   - Data Management with Cassandra: Integrated Cassandra to store processed data, ensuring high availability and efficient data retrieval.
   - Service Mesh with Istio: Utilized Istio for service discovery, load balancing, and secure communication, enhancing system reliability and observability.
