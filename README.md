# Data Engineer

### Education
Masters of Technology in Software Engineering

### Work Experience
Data Engineer @ WinZO Games Pvt. Limited
- Scalable Data Pipeline Management: Optimized data processing
pipelines using Apache Spark, handling 100+ TB of data daily
to support 60 million user transactions with low-latency access.
Designed and implemented Databricks workflows to process and
analyze large-scale data, ensuring optimized performance and scal-
ability for real-time business needs. Collaborated with data sci-
entists and analysts to deliver clean and accessible datasets for
advanced analytics and reporting. Automated CI/CD workflows
for ETL pipelines, enabling seamless deployment and reducing
time-to-production by 30
- Spark Job Monitoring and Alerting: Developed an advanced
monitoring system for Spark batch jobs using Pushgateway and
Prometheus, enabling real-time alerting and comprehensive mon-
itoring of Spark job health. This system has drastically improved
job reliability and response times, ensuring proactive issue resolu-
tion across large-scale data workflows.
- Cost and Performance Optimization: Led a POC comparing
Spark Jobs on EKS with EMR clusters, analyzing cost-efficiency
and core-hour metrics to inform resource allocation strategies.
Migrated complex batch pipelines to AWS Kubernetes, ensuring
scalability, cost-efficiency, and robust cloud architecture.
- Enhanced Data Quality with Complex Ingestion Pipelines: Built
and managed complex CDC ingestion pipelines with robust data
integrity checks, and alerting mechanisms, processing 600+ mil-
lion daily updates via Kafka. Migrated real-time Cassandra in-
gestion from EMR to AWS ECS, leveraging Docker for improved
scalability and operational efficiency.
- Kafka Streaming: Developed and maintained real-time data
pipelines using Kafka Streams, enabling reliable ingestion of 600+
million daily updates with advanced enrichment and deduplica-
tion mechanisms.

Data Engineer @ SG Analytics
- Built scalable ETL pipelines to extract, transform, and load
structured and semi-structured data into Redshift for analytics
teams. Developed Python-based scripts to automate data inte-
gration tasks and improve pipeline reliability, achieving a 20De-
signed and implemented SQL-based solutions for complex busi-
ness queries, improving report generation performance by 50
   Assisted in data modeling and created a comprehensive database
design from scratch, providing a foundation for database devel-
opment. Leveraged Tableau to deliver performance insights, en-
hancing operational efficiency and decision-making.

### Projects
- Scalable Big Data Processing System using Microser-
vices and Istio
Developed a microservices-based big data processing system using
Kafka, Spark Streaming, and Cassandra, managed through Istio for
secure and efficient service communication
• Microservices Implementation: Designed and deployed microser-
vices for data ingestion, processing, and storage using Docker and
Kubernetes, enabling scalable and modular architecture.
• Real-time Data Processing: Implemented Apache Spark Stream-
ing in Scala to process real-time data streams from Kafka, achiev-
ing low-latency and high-throughput processing.
• Data Management with Cassandra: Integrated Cassandra to store
processed data, ensuring high availability and efficient data re-
trieval.
• Service Mesh with Istio: Utilized Istio for service discovery, load
balancing, and secure communication, enhancing system reliabil-
ity and observability.
